{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d2aa420d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "#%conda install --yes jupyter\n",
    "#%conda install --yes pytorch torchvision torchaudio pytorch-cuda=11.7 -c pytorch -c nvidia\n",
    "%conda list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c56940a6-7cfc-4d2b-867c-d3125e1e7939",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-16T13:49:48.900292Z",
     "iopub.status.busy": "2023-05-16T13:49:48.899953Z",
     "iopub.status.idle": "2023-05-16T13:49:53.988504Z",
     "shell.execute_reply": "2023-05-16T13:49:53.987528Z",
     "shell.execute_reply.started": "2023-05-16T13:49:48.900234Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jack5\\VSCProjects\\DataMiningChallenge\\.conda\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: 'Could not find module 'C:\\Users\\Jack5\\VSCProjects\\DataMiningChallenge\\.conda\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from  torch.utils.data import DataLoader\n",
    "\n",
    "import albumentations as A\n",
    "import albumentations.pytorch.transforms as Atorch\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "BASEDIR = Path(\"\")\n",
    "fn = BASEDIR / \"train_eval.hdf5\"\n",
    "\n",
    "# WICHTIG: Nur so viele CPUs benutzen wie unserem Job zugeteilt sind.\n",
    "#   Sonst wird alles *sehr* langsam!\n",
    "N_CPUS = int(os.getenv(\"SLURM_CPUS_PER_TASK\", 1))\n",
    "torch.set_num_threads(N_CPUS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "daf934d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2b70afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "objectWithMask = 0\n",
    "objectWithPost_fire = 0\n",
    "objectWithPre_fire = 0\n",
    "\n",
    "objectsSummary = []\n",
    "currentObject = {}\n",
    "\n",
    "def listObject(obj, indent=0):\n",
    "    global objectWithMask\n",
    "    global objectWithPost_fire\n",
    "    global objectWithPre_fire\n",
    "    global objectsSummary\n",
    "    global currentObject\n",
    "\n",
    "    \n",
    "    \n",
    "    for name, thing in obj.items():\n",
    "        if indent == 0:\n",
    "            currentObject = { \"name\" : \"\", \"mask\": False, \"pre_fire\" : False, \"post_fire\": False}\n",
    "\n",
    "        if isinstance(thing, h5py.Group):\n",
    "            if indent == 0:\n",
    "                currentObject[\"name\"] = name\n",
    "            listObject(thing, indent+1)\n",
    "            \n",
    "        else:\n",
    "            if name == \"mask\":\n",
    "                currentObject[\"mask\"] = True\n",
    "                objectWithMask += 1\n",
    "            elif name == \"post_fire\":\n",
    "                currentObject[\"post_fire\"] = True\n",
    "                objectWithPost_fire += 1\n",
    "            elif name == \"pre_fire\":\n",
    "                currentObject[\"pre_fire\"] = True\n",
    "                objectWithPre_fire += 1\n",
    "            else:\n",
    "                print(name)\n",
    "    \n",
    "        if indent == 0:\n",
    "            objectsSummary.append(currentObject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32874830",
   "metadata": {},
   "outputs": [],
   "source": [
    "objectWithMask = 0\n",
    "objectWithPost_fire = 0\n",
    "objectWithPre_fire = 0\n",
    "\n",
    "objectsSummary = []\n",
    "currentObject = {}\n",
    "\n",
    "with h5py.File(fn, \"r\") as fd:\n",
    "    listObject(fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecf4ccf0-cf12-4da0-91ca-cf0059d9bf99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-16T13:49:53.990505Z",
     "iopub.status.busy": "2023-05-16T13:49:53.990032Z",
     "iopub.status.idle": "2023-05-16T13:49:54.001080Z",
     "shell.execute_reply": "2023-05-16T13:49:54.000423Z",
     "shell.execute_reply.started": "2023-05-16T13:49:53.990480Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FiresDataset(torch.utils.data.Dataset):\n",
    "    COORDS = {\"x\": range(512), \"y\": range(512), \"band\": [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"8a\", \"9\", \"11\", \"12\"]}\n",
    "    \n",
    "    def __init__(self, filename, folds=(0, 1, 2, 3, 4), exclude_pre=False, transform=None):\n",
    "        self._filename = filename\n",
    "        self._fd = h5py.File(filename, \"r\")\n",
    "        self._transform = transform\n",
    "        self._names = []        \n",
    "        for name in self._fd:\n",
    "            if self._fd[name].attrs[\"fold\"] not in folds:\n",
    "                continue\n",
    "            self._names.append((name, \"post_fire\"))\n",
    "            if \"pre_fire\" in self._fd[name] and not exclude_pre:\n",
    "                self._names.append((name, \"pre_fire\"))\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        name, state = self._names[idx]\n",
    "        data = self._fd[name][state][...].astype(\"float32\") / 10000.0\n",
    "        if state == \"pre_fire\":\n",
    "            mask = np.zeros((512, 512), dtype=\"float32\")\n",
    "        else:\n",
    "            mask = self._fd[name][\"mask\"][..., 0].astype(\"float32\")\n",
    "            \n",
    "        b2 = data[..., 1]\n",
    "        b3 = data[..., 2]\n",
    "        b4 = data[..., 3]\n",
    "        b6 = data[..., 5]\n",
    "        b7 = data[..., 6]\n",
    "        b8a = data[..., 8]\n",
    "        b11 = data[..., 10]\n",
    "        b12 = data[..., 11]\n",
    "\n",
    "        # Indices taken from https://www.mdpi.com/2072-4.astype(\"float32\") / 10000.092/14/7/1727\n",
    "        #\n",
    "        # NBR\n",
    "        nbr = (b12 - b8a) / (b12 + b8a + 1.0e-8)\n",
    "        \n",
    "        # MIRBI\n",
    "        mirbi = 10 * b12 - 9.8 * b11 + 2.0\n",
    "\n",
    "        # BAIS2:\n",
    "        c1 = 1 - np.sqrt((b6 * b7 * b8a) / (b4 + 1.0e-8))\n",
    "        c2 = (b12 - b8a) / np.sqrt(b12 + b8a + 1.0e-8) + 1\n",
    "        bais2 = (c1 * c2)        \n",
    "        \n",
    "        # NBR+:        \n",
    "        nbr_plus = ((b12 - b8a - b3 - b2) / (b12 + b8a + b3 + b2 + 1.0e-8))\n",
    "\n",
    "        # Stack indices into a new image in CHW format.\n",
    "        image =  np.stack((nbr, mirbi, bais2, nbr_plus))\n",
    "\n",
    "        if self._transform:\n",
    "            # Transpose image so we get HWC instead of CHW format.\n",
    "            # Transform is responsible for transposing back as required by PyTorch.\n",
    "            image = image.transpose((1, 2, 0))\n",
    "            xfrm = self._transform(image=image, mask=mask)\n",
    "            image, mask = xfrm[\"image\"], xfrm[\"mask\"]\n",
    "        return {\"image\": image, \"mask\": mask[None, :]}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7f8b3a0b-d72b-415e-b34e-44141b07d7cc",
   "metadata": {},
   "source": [
    "Wir augmentieren die Trainingsdaten in dem wir jedes Bild (mit Wahrscheinlichkeit 0.5):\n",
    "\n",
    "* Horizontal spiegeln\n",
    "* Vertical spiegeln\n",
    "* Transponieren\n",
    "* Um 90Â° rotieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3ab4dc7-0fb6-4f6f-be47-20a48e6b9c7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-16T13:51:05.594538Z",
     "iopub.status.busy": "2023-05-16T13:51:05.594219Z",
     "iopub.status.idle": "2023-05-16T13:51:05.605610Z",
     "shell.execute_reply": "2023-05-16T13:51:05.604719Z",
     "shell.execute_reply.started": "2023-05-16T13:51:05.594512Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FireModel(pl.LightningModule):\n",
    "    def __init__(self, in_channels=4, batch_size=16, lr=0.000025, **kwargs):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size        \n",
    "        self.model = smp.UnetPlusPlus(in_channels=in_channels, \n",
    "                                      classes=1,\n",
    "                                      encoder_depth=3,\n",
    "                                      encoder_weights=\"imagenet\",\n",
    "                                      decoder_channels=[256, 128, 64],\n",
    "                                      **kwargs)\n",
    "        # for image segmentation dice loss is a good first choice\n",
    "        self.loss_fn = smp.losses.DiceLoss(smp.losses.BINARY_MODE, from_logits=True)\n",
    "\n",
    "    def forward(self, image):\n",
    "        return self.model(image)\n",
    "\n",
    "    def shared_step(self, batch, stage):      \n",
    "        image, mask = batch[\"image\"], batch[\"mask\"]\n",
    "\n",
    "        logits = self.forward(image)\n",
    "        \n",
    "        loss = self.loss_fn(logits, mask)\n",
    "        \n",
    "        metrics = {}\n",
    "        metrics[f\"{stage}_loss\"] = loss\n",
    "        \n",
    "        prob_mask = logits.sigmoid()\n",
    "        pred_mask = (prob_mask > 0.5).long()\n",
    "        tp, fp, fn, tn = smp.metrics.get_stats(pred_mask.long(), mask.long(), mode=\"binary\")        \n",
    "        metrics[f\"{stage}_iou\"] = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro-imagewise\")\n",
    "\n",
    "        self.log_dict(metrics, prog_bar=True)                  \n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self.shared_step(batch, \"train\")        \n",
    "\n",
    "    def train_dataloader(self):\n",
    "        train_xfrm = A.Compose([\n",
    "            A.VerticalFlip(p=0.5),       \n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.Transpose(p=0.5),\n",
    "            A.RandomRotate90(p=0.5),\n",
    "            Atorch.ToTensorV2()\n",
    "        ])\n",
    "\n",
    "        result = DataLoader(\n",
    "            FiresDataset(fn, folds=[1, 2, 3, 4], transform=train_xfrm, exclude_pre=True),\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=N_CPUS,\n",
    "            shuffle=True,\n",
    "            pin_memory=True,\n",
    "            drop_last=True,\n",
    "        )\n",
    "        return result\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        result = DataLoader(\n",
    "            FiresDataset(fn, folds=[0], exclude_pre=True),\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=N_CPUS,\n",
    "            shuffle=False,\n",
    "            pin_memory=True,\n",
    "            drop_last=False,\n",
    "        )\n",
    "        return result\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self.shared_step(batch, \"valid\")\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return self.shared_step(batch, \"test\")\n",
    "                \n",
    "    def configure_optimizers(self):\n",
    "        # TODO: Can we do better? We should probably implement a learning rate schedule?\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "20d5c511-4bc4-4ed6-bb72-ac7749d0450e",
   "metadata": {},
   "source": [
    "## Modell erstellen\n",
    "\n",
    "Entweder wir laden einen vorherigen Checkpoint und setzen das Training fort, oder wir erstellen ein neues (leeres) Modell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49cd31b0-bdcd-4171-be3a-7db6b5c2758d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-16T13:51:06.724188Z",
     "iopub.status.busy": "2023-05-16T13:51:06.723895Z",
     "iopub.status.idle": "2023-05-16T13:51:07.279013Z",
     "shell.execute_reply": "2023-05-16T13:51:07.278209Z",
     "shell.execute_reply.started": "2023-05-16T13:51:06.724162Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    model = FireModel.load_from_checkpoint(\"lightning_logs/version_19/checkpoints/epoch=19-step=520.ckpt\")\n",
    "else:\n",
    "    model = FireModel(lr=0.001)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "08b04c57-657e-4d0c-85cb-ae3668b91b49",
   "metadata": {},
   "source": [
    "## Trainieren\n",
    "\n",
    "Anstelle einer Trainingsschleife nutzen wir den PyTorch Lightning `Trainer` um das Trainieren zu koordinieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5bd25d3-21ae-48e6-a197-0756aaf879da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-16T13:51:08.399258Z",
     "iopub.status.busy": "2023-05-16T13:51:08.398976Z",
     "iopub.status.idle": "2023-05-16T13:51:08.506668Z",
     "shell.execute_reply": "2023-05-16T13:51:08.506045Z",
     "shell.execute_reply.started": "2023-05-16T13:51:08.399229Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(log_every_n_steps=5, max_epochs=20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fd571980-429a-455e-8d7d-8450ae3d207f",
   "metadata": {},
   "source": [
    "Training starten bis die maximale Anzahl an Epochen erreicht ist oder das Training stagniert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "An invalid dataloader was returned from `FireModel.val_dataloader()`. Found <torch.utils.data.dataloader.DataLoader object at 0x00000217093D6B00>.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:383\u001b[0m, in \u001b[0;36m_check_dataloader_iterable\u001b[1;34m(dataloader, source, trainer_fn)\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 383\u001b[0m     \u001b[39miter\u001b[39;49m(dataloader)  \u001b[39m# type: ignore[call-overload]\u001b[39;00m\n\u001b[0;32m    384\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    385\u001b[0m     \u001b[39m# A prefix in the message to disambiguate between the train- and (optional) val dataloader that .fit() accepts\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:441\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 441\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 388\u001b[0m \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:1042\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1036\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1040\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1042\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[0;32m   1043\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n",
      "File \u001b[1;32mc:\\Users\\Jack5\\VSCProjects\\DataMiningChallenge\\.conda\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n",
      "File \u001b[1;32mc:\\Users\\Jack5\\VSCProjects\\DataMiningChallenge\\.conda\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
      "File \u001b[1;32mc:\\Users\\Jack5\\VSCProjects\\DataMiningChallenge\\.conda\\lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_win32\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[1;32m--> 336\u001b[0m \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[1;32mc:\\Users\\Jack5\\VSCProjects\\DataMiningChallenge\\.conda\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     92\u001b[0m     reduction\u001b[39m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     reduction\u001b[39m.\u001b[39;49mdump(process_obj, to_child)\n\u001b[0;32m     94\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Jack5\\VSCProjects\\DataMiningChallenge\\.conda\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[39m\u001b[39m\u001b[39m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m ForkingPickler(file, protocol)\u001b[39m.\u001b[39;49mdump(obj)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\h5py\\_hl\\base.py:368\u001b[0m, in \u001b[0;36mHLObject.__getnewargs__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    359\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Disable pickle.\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \n\u001b[0;32m    361\u001b[0m \u001b[39mHandles for HDF5 objects can't be reliably deserialised, because the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[39mlimitations, look at the h5pickle project on PyPI.\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 368\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mh5py objects cannot be pickled\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: h5py objects cannot be pickled",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trainer\u001b[39m.\u001b[39;49mvalidate(model\u001b[39m=\u001b[39;49mmodel, verbose\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pytorch_lightning\\trainer\\trainer.py:609\u001b[0m, in \u001b[0;36mTrainer.validate\u001b[1;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[0;32m    607\u001b[0m     model \u001b[39m=\u001b[39m _maybe_unwrap_optimized(model)\n\u001b[0;32m    608\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m_lightning_module \u001b[39m=\u001b[39m model\n\u001b[1;32m--> 609\u001b[0m \u001b[39mreturn\u001b[39;00m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[0;32m    610\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_impl, model, dataloaders, ckpt_path, verbose, datamodule\n\u001b[0;32m    611\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pytorch_lightning\\trainer\\call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     43\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 44\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     46\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n\u001b[0;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pytorch_lightning\\trainer\\trainer.py:652\u001b[0m, in \u001b[0;36mTrainer._validate_impl\u001b[1;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[0;32m    647\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_connector\u001b[39m.\u001b[39mattach_data(model, val_dataloaders\u001b[39m=\u001b[39mdataloaders, datamodule\u001b[39m=\u001b[39mdatamodule)\n\u001b[0;32m    649\u001b[0m ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_select_ckpt_path(\n\u001b[0;32m    650\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn, ckpt_path, model_provided\u001b[39m=\u001b[39mmodel_provided, model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    651\u001b[0m )\n\u001b[1;32m--> 652\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49mckpt_path)\n\u001b[0;32m    653\u001b[0m \u001b[39m# remove the tensors from the validation results\u001b[39;00m\n\u001b[0;32m    654\u001b[0m results \u001b[39m=\u001b[39m convert_tensors_to_scalars(results)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pytorch_lightning\\trainer\\trainer.py:935\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_signal_connector\u001b[39m.\u001b[39mregister_signal_handlers()\n\u001b[0;32m    932\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m    933\u001b[0m \u001b[39m# RUN THE TRAINER\u001b[39;00m\n\u001b[0;32m    934\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m--> 935\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_stage()\n\u001b[0;32m    937\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m    938\u001b[0m \u001b[39m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[0;32m    939\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m    940\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: trainer tearing down\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pytorch_lightning\\trainer\\trainer.py:971\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    968\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mbarrier(\u001b[39m\"\u001b[39m\u001b[39mrun-stage\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    970\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluating:\n\u001b[1;32m--> 971\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_evaluation_loop\u001b[39m.\u001b[39;49mrun()\n\u001b[0;32m    972\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredicting:\n\u001b[0;32m    973\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict_loop\u001b[39m.\u001b[39mrun()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pytorch_lightning\\loops\\utilities.py:177\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    175\u001b[0m     context_manager \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mno_grad\n\u001b[0;32m    176\u001b[0m \u001b[39mwith\u001b[39;00m context_manager():\n\u001b[1;32m--> 177\u001b[0m     \u001b[39mreturn\u001b[39;00m loop_run(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pytorch_lightning\\loops\\evaluation_loop.py:98\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[39m@_no_grad_context\u001b[39m\n\u001b[0;32m     97\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[_OUT_DICT]:\n\u001b[1;32m---> 98\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msetup_data()\n\u001b[0;32m     99\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mskip:\n\u001b[0;32m    100\u001b[0m         \u001b[39mreturn\u001b[39;00m []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pytorch_lightning\\loops\\evaluation_loop.py:168\u001b[0m, in \u001b[0;36m_EvaluationLoop.setup_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_max_batches \u001b[39m=\u001b[39m []\n\u001b[0;32m    167\u001b[0m \u001b[39mfor\u001b[39;00m dl \u001b[39min\u001b[39;00m combined_loader\u001b[39m.\u001b[39mflattened:\n\u001b[1;32m--> 168\u001b[0m     _check_dataloader_iterable(dl, source, trainer_fn)\n\u001b[0;32m    169\u001b[0m     dl \u001b[39m=\u001b[39m _process_dataloader(trainer, dl)\n\u001b[0;32m    170\u001b[0m     dataloaders\u001b[39m.\u001b[39mappend(dl)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:399\u001b[0m, in \u001b[0;36m_check_dataloader_iterable\u001b[1;34m(dataloader, source, trainer_fn)\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_overridden(source\u001b[39m.\u001b[39mname, source\u001b[39m.\u001b[39minstance):\n\u001b[0;32m    393\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    394\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAn invalid dataloader was passed to `Trainer.\u001b[39m\u001b[39m{\u001b[39;00mtrainer_fn\u001b[39m}\u001b[39;00m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00mprefix\u001b[39m}\u001b[39;00m\u001b[39mdataloaders=...)`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    395\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m Found \u001b[39m\u001b[39m{\u001b[39;00mdataloader\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    396\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m Either pass the dataloader to the `.\u001b[39m\u001b[39m{\u001b[39;00mtrainer_fn\u001b[39m}\u001b[39;00m\u001b[39m()` method OR implement\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    397\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m `def \u001b[39m\u001b[39m{\u001b[39;00msource\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m(self):` in your LightningModule/LightningDataModule.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    398\u001b[0m     )\n\u001b[1;32m--> 399\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    400\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAn invalid dataloader was returned from `\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(source\u001b[39m.\u001b[39minstance)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00msource\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m()`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    401\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m Found \u001b[39m\u001b[39m{\u001b[39;00mdataloader\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    402\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: An invalid dataloader was returned from `FireModel.val_dataloader()`. Found <torch.utils.data.dataloader.DataLoader object at 0x00000217093D6B00>."
     ]
    }
   ],
   "source": [
    "trainer.validate(model=model, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5b5ecb-f320-4511-8cb0-6482a27be627",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-16T13:51:10.051546Z",
     "iopub.status.busy": "2023-05-16T13:51:10.051207Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name    | Type         | Params\n",
      "-----------------------------------------\n",
      "0 | model   | UnetPlusPlus | 23.1 M\n",
      "1 | loss_fn | DiceLoss     | 0     \n",
      "-----------------------------------------\n",
      "23.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "23.1 M    Total params\n",
      "92.535    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b96a1be0ec0f47ad9da249821e0a18b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "An invalid dataloader was returned from `FireModel.val_dataloader()`. Found <torch.utils.data.dataloader.DataLoader object at 0x0000021A8A77F1F0>.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:383\u001b[0m, in \u001b[0;36m_check_dataloader_iterable\u001b[1;34m(dataloader, source, trainer_fn)\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 383\u001b[0m     \u001b[39miter\u001b[39;49m(dataloader)  \u001b[39m# type: ignore[call-overload]\u001b[39;00m\n\u001b[0;32m    384\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    385\u001b[0m     \u001b[39m# A prefix in the message to disambiguate between the train- and (optional) val dataloader that .fit() accepts\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:441\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 441\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 388\u001b[0m \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:1042\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1036\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1040\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1042\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[0;32m   1043\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n",
      "File \u001b[1;32mc:\\Users\\Jack5\\VSCProjects\\DataMiningChallenge\\.conda\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n",
      "File \u001b[1;32mc:\\Users\\Jack5\\VSCProjects\\DataMiningChallenge\\.conda\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
      "File \u001b[1;32mc:\\Users\\Jack5\\VSCProjects\\DataMiningChallenge\\.conda\\lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_win32\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[1;32m--> 336\u001b[0m \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[1;32mc:\\Users\\Jack5\\VSCProjects\\DataMiningChallenge\\.conda\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     92\u001b[0m     reduction\u001b[39m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     reduction\u001b[39m.\u001b[39;49mdump(process_obj, to_child)\n\u001b[0;32m     94\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Jack5\\VSCProjects\\DataMiningChallenge\\.conda\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[39m\u001b[39m\u001b[39m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m ForkingPickler(file, protocol)\u001b[39m.\u001b[39;49mdump(obj)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\h5py\\_hl\\base.py:368\u001b[0m, in \u001b[0;36mHLObject.__getnewargs__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    359\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Disable pickle.\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \n\u001b[0;32m    361\u001b[0m \u001b[39mHandles for HDF5 objects can't be reliably deserialised, because the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[39mlimitations, look at the h5pickle project on PyPI.\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 368\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mh5py objects cannot be pickled\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: h5py objects cannot be pickled",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(model)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pytorch_lightning\\trainer\\trainer.py:520\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    518\u001b[0m model \u001b[39m=\u001b[39m _maybe_unwrap_optimized(model)\n\u001b[0;32m    519\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m_lightning_module \u001b[39m=\u001b[39m model\n\u001b[1;32m--> 520\u001b[0m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[0;32m    521\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[0;32m    522\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pytorch_lightning\\trainer\\call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     43\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 44\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     46\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n\u001b[0;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pytorch_lightning\\trainer\\trainer.py:559\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    549\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_connector\u001b[39m.\u001b[39mattach_data(\n\u001b[0;32m    550\u001b[0m     model, train_dataloaders\u001b[39m=\u001b[39mtrain_dataloaders, val_dataloaders\u001b[39m=\u001b[39mval_dataloaders, datamodule\u001b[39m=\u001b[39mdatamodule\n\u001b[0;32m    551\u001b[0m )\n\u001b[0;32m    553\u001b[0m ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_select_ckpt_path(\n\u001b[0;32m    554\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn,\n\u001b[0;32m    555\u001b[0m     ckpt_path,\n\u001b[0;32m    556\u001b[0m     model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    557\u001b[0m     model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    558\u001b[0m )\n\u001b[1;32m--> 559\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49mckpt_path)\n\u001b[0;32m    561\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[0;32m    562\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pytorch_lightning\\trainer\\trainer.py:935\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_signal_connector\u001b[39m.\u001b[39mregister_signal_handlers()\n\u001b[0;32m    932\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m    933\u001b[0m \u001b[39m# RUN THE TRAINER\u001b[39;00m\n\u001b[0;32m    934\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m--> 935\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_stage()\n\u001b[0;32m    937\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m    938\u001b[0m \u001b[39m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[0;32m    939\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m    940\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: trainer tearing down\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pytorch_lightning\\trainer\\trainer.py:976\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    974\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining:\n\u001b[0;32m    975\u001b[0m     \u001b[39mwith\u001b[39;00m isolate_rng():\n\u001b[1;32m--> 976\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_sanity_check()\n\u001b[0;32m    977\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mset_detect_anomaly(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_detect_anomaly):\n\u001b[0;32m    978\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_loop\u001b[39m.\u001b[39mrun()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1005\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1002\u001b[0m call\u001b[39m.\u001b[39m_call_callback_hooks(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mon_sanity_check_start\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1004\u001b[0m \u001b[39m# run eval step\u001b[39;00m\n\u001b[1;32m-> 1005\u001b[0m val_loop\u001b[39m.\u001b[39;49mrun()\n\u001b[0;32m   1007\u001b[0m call\u001b[39m.\u001b[39m_call_callback_hooks(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mon_sanity_check_end\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1009\u001b[0m \u001b[39m# reset logger connector\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pytorch_lightning\\loops\\utilities.py:177\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    175\u001b[0m     context_manager \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mno_grad\n\u001b[0;32m    176\u001b[0m \u001b[39mwith\u001b[39;00m context_manager():\n\u001b[1;32m--> 177\u001b[0m     \u001b[39mreturn\u001b[39;00m loop_run(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pytorch_lightning\\loops\\evaluation_loop.py:98\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[39m@_no_grad_context\u001b[39m\n\u001b[0;32m     97\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[_OUT_DICT]:\n\u001b[1;32m---> 98\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msetup_data()\n\u001b[0;32m     99\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mskip:\n\u001b[0;32m    100\u001b[0m         \u001b[39mreturn\u001b[39;00m []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pytorch_lightning\\loops\\evaluation_loop.py:168\u001b[0m, in \u001b[0;36m_EvaluationLoop.setup_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_max_batches \u001b[39m=\u001b[39m []\n\u001b[0;32m    167\u001b[0m \u001b[39mfor\u001b[39;00m dl \u001b[39min\u001b[39;00m combined_loader\u001b[39m.\u001b[39mflattened:\n\u001b[1;32m--> 168\u001b[0m     _check_dataloader_iterable(dl, source, trainer_fn)\n\u001b[0;32m    169\u001b[0m     dl \u001b[39m=\u001b[39m _process_dataloader(trainer, dl)\n\u001b[0;32m    170\u001b[0m     dataloaders\u001b[39m.\u001b[39mappend(dl)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:399\u001b[0m, in \u001b[0;36m_check_dataloader_iterable\u001b[1;34m(dataloader, source, trainer_fn)\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_overridden(source\u001b[39m.\u001b[39mname, source\u001b[39m.\u001b[39minstance):\n\u001b[0;32m    393\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    394\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAn invalid dataloader was passed to `Trainer.\u001b[39m\u001b[39m{\u001b[39;00mtrainer_fn\u001b[39m}\u001b[39;00m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00mprefix\u001b[39m}\u001b[39;00m\u001b[39mdataloaders=...)`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    395\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m Found \u001b[39m\u001b[39m{\u001b[39;00mdataloader\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    396\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m Either pass the dataloader to the `.\u001b[39m\u001b[39m{\u001b[39;00mtrainer_fn\u001b[39m}\u001b[39;00m\u001b[39m()` method OR implement\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    397\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m `def \u001b[39m\u001b[39m{\u001b[39;00msource\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m(self):` in your LightningModule/LightningDataModule.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    398\u001b[0m     )\n\u001b[1;32m--> 399\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    400\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAn invalid dataloader was returned from `\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(source\u001b[39m.\u001b[39minstance)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00msource\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m()`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    401\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m Found \u001b[39m\u001b[39m{\u001b[39;00mdataloader\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    402\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: An invalid dataloader was returned from `FireModel.val_dataloader()`. Found <torch.utils.data.dataloader.DataLoader object at 0x0000021A8A77F1F0>."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "trainer.fit(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
